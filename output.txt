--- File Structure ---
main/
  layer.py
  main.py
  network.py

--- File Contents ---

## main\layer.py ##
import numpy as np
import math
class Layer:
    last_neuron_data: np.ndarray

    def __init__(self, dimin, dimout):
        self.matrix = 2 * np.random.rand(dimout, dimin) - 1
        self.dmatrix = np.zeros((dimout, dimin))
        self.bias = 2*np.random.rand(dimout,) - 1
        self.dbias = np.zeros((dimout,))
        
    def step(self, vectorIn):
        v = self.matrix @ vectorIn
        v += self.bias
        for i, num in enumerate(v):
            v[i] = self.activation(num)
        self.last_neuron_data = v
        return v

    
    def layer_bpropag(self, neurondeltas, previous_layer):
        delta = self.activation_derivative(self.last_neuron_data)
        self.dbias += neurondeltas * delta
        self.dmatrix += np.outer(neurondeltas * delta, previous_layer)
        previous_neurondeltas = np.transpose(self.matrix) @ (neurondeltas * delta)

        return(previous_neurondeltas)
        
    def modify(self, deltat, n):
        self.matrix += self.dmatrix * deltat / n
        self.dmatrix *= 0
        self.bias += self.dbias * deltat / n
        self.dbias *= 0

    def activation(self,num) -> float:
        '''if num > 0:
            return num
        else: 
            return(0)
        '''
        
        return(1 / (1 + math.exp(-num)))
    
    def activation_derivative(self,num) -> float:
        #if num >= 0:
        #    return 1
        #else: 
        #    return(0)
        return(num * (1 - num))

## main\main.py ##
import numpy as np
from network import Network
# import math
from layer import Layer

#myNetwork = Network([2, 3, 8, 4])
#myNetwork.compute(np.array([1,2]))

myNetwork = Network([2, 4, 1])
for _ in range(1000):
    err = myNetwork.learn(np.array([[0, 0], [0, 1], [1, 0], [1, 1]]), np.array([[0], [1], [1], [0]]), 0.0005)
    print(err)

print(myNetwork.compute(np.array([1,0])))
print(myNetwork.compute(np.array([0,0])))
print(myNetwork.compute(np.array([1,1])))
print(myNetwork.compute(np.array([0,1])))

## main\network.py ##
import numpy as np
from layer import Layer
import math

class Network:
    def __init__(self, layers):
        self.layers = layers
        self.layerslst = []
        for i in range(len(self.layers) - 1):
            self.layerslst.append(Layer(dimin = self.layers[i], dimout = self.layers[i + 1]))
         
    def compute(self, inp):
        for layer_ in self.layerslst:
            inp = layer_.step(inp)
            #print(inp)
        return inp
    
    def learn(self, inputarr, outputarr, deltat):
        err = 0
        for i in range (len(inputarr)):
            estimate = self.compute(inputarr[i])
            neurondeltas = 2 * (outputarr[i] - estimate)
            err += np.sum((outputarr[i] - estimate)**2)
            for j in range(len(self.layers)-2, 0, -1):
                neurondeltas = self.layerslst[j].layer_bpropag(neurondeltas, self.layerslst[j - 1].last_neuron_data)
            neurondeltas = self.layerslst[0].layer_bpropag(neurondeltas, inputarr[i])    

        for j in range(len(self.layerslst)):
            self.layerslst[j].modify(deltat, len(inputarr)) 
        return err / len(inputarr)
    
